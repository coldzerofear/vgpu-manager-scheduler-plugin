apiVersion: v1
kind: ServiceAccount
metadata:
  name: vgpu-manager-scheduler-plugin
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: vgpu-manager-scheduler-plugin-as-kube-scheduler
subjects:
  - kind: ServiceAccount
    name: vgpu-manager-scheduler-plugin
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:kube-scheduler
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: vgpu-manager-scheduler-plugin-as-volume-scheduler
subjects:
  - kind: ServiceAccount
    name: vgpu-manager-scheduler-plugin
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:volume-scheduler
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: vgpu-manager-scheduler-plugin-as-daemon-set-controller
subjects:
  - kind: ServiceAccount
    name: vgpu-manager-scheduler-plugin
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: system:controller:daemon-set-controller
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: vgpu-manager-scheduler-plugin:leader-election-role
  namespace: kube-system
rules:
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get","list","watch","create","update","delete"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get","list","watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: vgpu-manager-scheduler-plugin:node-role
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get","list","watch","update","patch"]
  - apiGroups: [""]
    resources: ["nodes/status"]
    verbs: ["patch","update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: vgpu-manager-scheduler-plugin-as-node-role
subjects:
  - kind: ServiceAccount
    name: vgpu-manager-scheduler-plugin
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: vgpu-manager-scheduler-plugin:node-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: vgpu-manager-scheduler-plugin-as-leader-election-role
  namespace: kube-system
subjects:
  - kind: ServiceAccount
    name: vgpu-manager-scheduler-plugin
    namespace: kube-system
roleRef:
  kind: Role
  name: vgpu-manager-scheduler-plugin:leader-election-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: vgpu-manager-scheduler-plugin-config
  namespace: kube-system
data:
  config.yaml: |
    apiVersion: kubescheduler.config.k8s.io/v1
    kind: KubeSchedulerConfiguration
    leaderElection:
      leaderElect: true
      resourceName: vgpu-manager-scheduler-plugin
      resourceNamespace: kube-system
    profiles:
      - schedulerName: vgpu-scheduler
        plugins:
          preFilter:
            enabled:
            - name: VGPUSchedulerPlugin
          filter:
            enabled:
            - name: VGPUSchedulerPlugin
          preScore:
            enabled:
            - name: VGPUSchedulerPlugin
          score:
            enabled:
            - name: VGPUSchedulerPlugin
              weight: 1
          bind:
            enabled:
            - name: VGPUSchedulerPlugin
            disabled:
            - name: DefaultBinder
        pluginConfig:
          - name: NodeResourcesFit
            args:
              ignoredResources: 
                - "nvidia.com/vgpu-number"
                - "nvidia.com/vgpu-cores"
                - "nvidia.com/vgpu-memory"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: vgpu-manager-scheduler-plugin
  name: vgpu-manager-scheduler-plugin
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: vgpu-manager-scheduler-plugin
  replicas: 1
  template:
    metadata:
      labels:
        vgpu-manager.io/ignore-webhook: "true"
        app: vgpu-manager-scheduler-plugin
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-role.kubernetes.io/master
                    operator: Exists
              - matchExpressions:
                  - key: node-role.kubernetes.io/control-plane
                    operator: Exists
      tolerations:
        - effect: NoSchedule
          operator: Exists
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          operator: Exists
          key: node-role.kubernetes.io/control-plane
        - effect: NoSchedule
          operator: Exists
          key: node.cloudprovider.kubernetes.io/uninitialized
      serviceAccountName: vgpu-manager-scheduler-plugin
      # Mark this pod as a critical add-on; when enabled, the critical add-on
      # scheduler reserves resources for critical add-on pods so that they can
      # be rescheduled after a failure.
      # See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/
      priorityClassName: system-node-critical
      terminationGracePeriodSeconds: 30
      restartPolicy: Always
      containers:
        - image: coldzerofear/vgpu-manager-scheduler-plugin:latest
          imagePullPolicy: IfNotPresent
          name: scheduler
          command:
            - scheduler-plugin
            - --config=/config/config.yaml
            - --v=3
          resources:
            requests:
              cpu: 100m
          volumeMounts:
            - name: scheduler-config
              mountPath: /config
          livenessProbe:
            failureThreshold: 8
            httpGet:
              path: /healthz
              port: 10259
              scheme: HTTPS
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 15
      volumes:
        - name: scheduler-config
          configMap:
            name: vgpu-manager-scheduler-plugin-config